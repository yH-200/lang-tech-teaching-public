{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Ãœberschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Aufgabenbeschreibung. Z.B.: \"Ãœbung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code Ã¤ndern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords Ã¤ndern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable Ã¤ndern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property Ã¤ndern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators Ã¤ndern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings Ã¤ndern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion Ã¤ndern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2021/2022\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"N-grams\"</i>\n",
    "    <br><br>\n",
    "    Deadline der Abgabe: <i #id=\"submission\">Freitag, 05.11.2021 (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization\n",
    "\n",
    "Each week you will receive a handout with some theoretical and/ or programming tasks related to NLP. You can also work on them at home, but be aware that in the practice class you have the opportunity to discuss and ask questions. <br>\n",
    "Each handout also contains homework. Working on these homework tasks and handing them in is not mandatory, but you can benefit from that in two ways: You get feedback on your solutions and a better understanding of the subject, and, more importantly, you have the chance to improve your final grade for the exam. If you hand in your solutions, we will grade them based on their quality. For each homework task there are points to collect depending on the amount\n",
    "of work you have to put into it. You will find the maximum number of points to gain for a task in its header. <br>\n",
    "Finally, if you want to hand in your solutions, please use the Moodle system. Please only submit Jupyter notebooks.\n",
    "The deadline for the homework is Thursday. Later submissions will not be graded.\n",
    "\n",
    "\n",
    "### Installation\n",
    "\n",
    "In order to be able to complete the exercises and the homework, you need to install Python (http://www.python.org) and Jupyter (https://jupyter.org). \n",
    "As we are working with the Natural Language Toolkit (NLTK), please also install NLTK (http://www.nltk.org) and its packages.\n",
    "\n",
    "For further information also refer to: <br>\n",
    "https://www.nltk.org/install.html <br>\n",
    "http://www.nltk.org/data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import*\n",
    "from nltk.book import*\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "Discuss in which of the following cases a frequency distribution may be used reasonably:\n",
    "1. To save a list of tokens.\n",
    "2. To count, how often each word type occurs in a given document.\n",
    "3. To find collocations in a text.\n",
    "4. To count, how often adjectives, nouns or verbs occur in a given text.\n",
    "5. To compute the number of occurrences of each item in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.2:</i> <br>\n",
    "</div>\n",
    "\n",
    "Discuss in which of the following cases a conditional frequency distribution may be used reasonably:\n",
    "1. To count how often each word type occurs in a given document, which belongs to a given category.\n",
    "2. To find collocations in a text.\n",
    "3. To count how often adjectives, nouns or verbs occur in a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.3:</i> <br>\n",
    "</div>\n",
    "\n",
    "Token/Type/Vocabulary: Which of the following statements are true?\n",
    "1. Every token is a type.\n",
    "2. The vocabulary of a text consists of all tokens.\n",
    "3. The vocabulary of a text consists of all types.\n",
    "4. The vocabulary of a text consists of the union of all tokens and all types.\n",
    "5. The vocabulary of a text consists of the intersection of all tokens and all types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.4:</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "Lists in Python: Let l and m be lists of words. Which of the following lines are syntactically correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: l.index(\"hi\") \n",
    "#2: [l] - 2\n",
    "#3: x = 1 + m\n",
    "#4: x = 1 & m\n",
    "#5: l[1,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.5:</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "Explore some texts provided by NLTK (to avoid slow reactions do the following with a sublist of text1, i.e.\n",
    "t = text1[:500]) and explain the meaning of the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = text1[:500]\n",
    "print(str(\"len:\"),len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted(t):\",sorted(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"set(t):\",set(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted(set(t)):\",sorted(set(t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(set(t)):\",len(set(t)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which types of the sentence \"Today it's nice weather. Is it not nice today :-)?\" are contained in the Chat Corpus of NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.6:</i> <br>\n",
    "</div>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.6.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Explain the following function, what does it compute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in text1.tokens if w.lower().startswith('e')]\n",
    "print(set(words[:10]))\n",
    "print('count:', len(words))\n",
    "print('count:', len(set(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.6.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the function above so that it extracts all words from a corpus that start and end with the letter 's' and consists out of 4 letters, the output should contain all found words and the count of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.6.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Another way of finding interesting tokens in a corpus is to see which ones do not occur in another corpus. Write a method that prints all tokens that only appear in a certain corpus, given another corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.7:</i> <br>\n",
    "</div>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.7.1</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Use a frequency distribution and print the vocabulary of Moby Dick (text1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.7.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Find the 20 most and least frequent words in Moby Dick (text1). Using the command fdist.hapaxes() you can also find words that only appear once (hapaxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.8:</i> <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.8.1</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Write a funtion that computes how many times the word \"lol\" appears in the chat corpus (text 5) and how much this is as a percentage of the total number of words in this text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.8.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Adapt the code from task 2.7.2 to find the 20 most common words in a corpus starting with 'th'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.8.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "We can also look at the distribution of word lengths in a text by creating a FreqDist out of a list of numbers, with each number being the length of the corresponding word in the text. <br>\n",
    "Compare the count and frequency of the most frequent word length in Moby Dick (text1) to those in Monty Python and the Holy Grail (text6)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Frequency Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.9:</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Write a function get_word_frequency that extracts the most frequent word with `n` letters from a corpus `c`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.10:</i> <br>\n",
    "</div>\n",
    "\n",
    "One of the corpora in NLTK is the US Presidential Inaugural Addresses. An interesting property of\n",
    "this collection is its time dimension: The corpus contains an address for each president."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.10.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the function below. Without executing the code on your PC, describe what the resulting chart shows. Then execute it to verify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((fileid[:4], len(w))\n",
    "    for fileid in inaugural.fileids()[:15]\n",
    "    for w in inaugural.words(fileid))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.10.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Enhance the function above so that it plots the number of distinct tokens (without duplicates) for the first 15 speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.10.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Let’s look at how the words “America” and “citizen” are used over time. Use a CFD and plot how often each of those two words are used in each inaugural address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.11:</i> <br>\n",
    "</div>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.11.1</i>\n",
    "</div>\n",
    "\n",
    "Pick 20 first names randomly – male and female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.11.2</i> \n",
    "</div>\n",
    "\n",
    "Fill in the table below: <br>\n",
    "\n",
    "| - | male   | female | sum\n",
    "|------|------|------|-----\n",
    "|  ends in 'a' | ? | ? | ?\n",
    "|  ends not with an 'a' | ? | ? | ?\n",
    "|  sum | ? | ? | ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.11.3</i>\n",
    "</div>\n",
    "\n",
    "Calculate the probability, that a name which ends in ’a’ is a female name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.11.4</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Use the conditional frequency distribution over the Names corpus to verify the hypothesis that first names ending with an ‘a’ are most likely female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.12:</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "Using the given conditional frequency distribution over bigrams from the Brown corpus, complete the method\n",
    "generate so that it generates sentences given a certain target word. Then change the underlying corpus\n",
    "(e.g. use the Book of Genesis corpus) and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a distribution of bigrams\n",
    "cfd = nltk.ConditionalFreqDist([(w1, w2) for (w1, w2) in nltk.bigrams(brown.words())])\n",
    "cfd['house']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(cfd, start, length):\n",
    "\n",
    "              \n",
    "generate(cfd, 'I', 10)\n",
    "generate(cfd, 'house', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.13:</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Compute the probability of the sentence \"the city is old\" under bigram models from two different nltk corpora. Under which corpus is the sentence more probable? Can you find (trial and error) a sentence that is more likely for the other corpus without being directly contained in it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.14:</i> <br>\n",
    "</div>\n",
    "\n",
    "Consider the following text: “Today it’s nice weather. Is it not nice today :-) ?” <br>\n",
    "1. What is the length of this text? What may be counted?\n",
    "2. What are reasonable tokens?\n",
    "3. State the types and the vocabulary of this short text according to your chosen tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.15:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.15.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the code below. Without executing it on your computer, what is the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Hello. This is a text. A text that contains sentences, which contain words. It has no greater meaning!\"\n",
    "for stc in nltk.sent_tokenize(s):\n",
    "    print(stc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.15.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the function above so that it extracts all tokens contained in String s. (Hint: Use the segmenter!) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">2.15.3</i> \n",
    "</div>\n",
    "\n",
    "Change the document in order to make it particularly difficult for the tokenizer to work correctly. Run it again and check how well it performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Submission guidelines*\n",
    "* *The submission has to be done by a team of two people. **Individual submissions will not be graded**.*\n",
    "* *Please state the **name and matriculation number of all team members** in every submission **clearly**.*\n",
    "* *Only **one team member should submit** the homework. If more than one version of the same homework is submitted by accident (submitted by more than one group member), please reach out to a tutor **as soon as possible**. Otherwise, the first submitted homework will be graded.*\n",
    "* *The submission must be in a Jupyter Notebook format (.ipynb). Submissions in **other formats will not be graded**.*\n",
    "* *It is not necessary to also submit the part of the exercise discussed by the tutor, please only submit the homework part.*\n",
    "* *If pictures need to be submitted, it is allowed to hand them in in a zip folder, together with the notebook. They should be added to the notebook like this: ``![example1](examplepicture1.PNG)`` (without apostrophs in a Markdown-Cell).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 2.1:</i>\n",
    "        ::: 6 Homework points :::</div>\n",
    "\n",
    "Implement a language guesser, i.e. a function that takes a given text and outputs the language it thinks the text is written in. The function should base its decision on the frequency of individual characters in each language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.1:* Implement a function get_language_cfd(languages, words) which takes a list of languages as an argument and returns a conditional frequency distribution where:\n",
    "* the languages are the conditions\n",
    "* the values are the lower case characters found in the words for each language <br>\n",
    "Inside the function you can access the UDHR corpus to get samples for several languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.2:* Develop an algorithm which calculates the overall score of a given text based on the frequency of characters accessible by language_model_cfd[language].freq(character). Implement a function guessLanguage that returns the most likely language for a given text according to your algorithm from the previous sub task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.3:* Test your implementation with the data text1, text2 and text3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_cfd(languages, words):\n",
    "    \"\"\"Build a ConditionalFrequencyDistribution of character frequencies in the UDHR corpus conditioned \n",
    "    on each language\"\"\"\n",
    "    \n",
    "\n",
    "def guess_language(language_model_cfd, text):\n",
    "    \"\"\"Returns the guessed language for the given text\"\"\"\n",
    "\n",
    "    \n",
    "languages = ['English', 'German_Deutsch', 'French_Francais']\n",
    "# build the language models\n",
    "# udhr contains the Universal Declaration of Human Rights in over 300 languages\n",
    "language_base = dict((language, udhr.words(language + '-Latin1')) for language in languages)\n",
    "language_model_cfd = get_language_cfd(languages, language_base)\n",
    "\n",
    "# print the models for visual inspection (you always should have a look at the data :)\n",
    "for language in languages:\n",
    "    for key in language_model_cfd[language].keys():\n",
    "        print(language, key, \"->\", language_model_cfd[language].freq(key))\n",
    "\n",
    "text1 = \"Peter had been to the office before they arrived.\"\n",
    "text2 = \"Si tu finis tes devoirs, je te donnerai des bonbons.\"\n",
    "text3 = \"Das ist ein schon recht langes deutsches Beispiel.\"\n",
    "\n",
    "# guess the language by comparing the frequency distributions\n",
    "print()\n",
    "print(guess_language(language_model_cfd, text1)) # English\n",
    "print()\n",
    "print(guess_language(language_model_cfd, text2)) # French_Francais\n",
    "print()\n",
    "print(guess_language(language_model_cfd, text3)) # German_Deutsch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function does not detect the correct language for at least two of these sentences, improve your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.4:* Discuss why English and German texts are difficult to distinguish with the given approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 2.2:</i>\n",
    "        ::: 4 Homework points :::</div>\n",
    "\n",
    "The previous language guesser was based on the frequency of characters. Implement alternative language guesser based on the following lexical units:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.2.1:* tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.2.2:* character bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.2.3:* token bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 2.3:</i>\n",
    "        ::: 1 extra exam bonus point :::</div>\n",
    "\n",
    "We will evaluate your system on unknown data. 1 extra exam bonus point will be awarded to the 3 teams who submitted the best system. The final results will be presented in the lecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
