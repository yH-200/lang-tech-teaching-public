{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2019/2020\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Part-of-speech-tagging\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Thursday, (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import*\n",
    "from nltk.book import*\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "Discuss which of the following concepts may be regarded as POS tags.\n",
    "1. word classes\n",
    "2. lexical categories\n",
    "3. verbs, nouns, adjectives\n",
    "4. present tense, past tense\n",
    "5. emotion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. True. POS tags are basically word classes.\n",
    "2. True, because lexical category is considered to be a synonym for word class.\n",
    "3. True, these word classes are standard POS.\n",
    "4. False. Some POS tagsets (e.g. Penn Treebank tagset) have subcategories for verbs that code tense but tense itself is not a part-of-speech.\n",
    "5. False, because “emotion” is not considered to be a word class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.2:</i> <br>\n",
    "</div>\n",
    "\n",
    "Which of the following statements are true? Find examples or counterexamples.\n",
    "1. Homographs may be used as synonyms.\n",
    "2. Homographs remain homographs regardless of their capitalization.\n",
    "3. Homographs belong to the same word class.\n",
    "4. Homographs have the same pronunciation.\n",
    "5. Homographs are spelled equally. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. False. Homographs have different meaning by definition, e.g. ’bat’ (an animal) vs ’bat’ (hitting instrument)\n",
    "2. False. As capitalization in English usually changes the meaning of a word, differently capitalized words are not considered to be spelled equally.\n",
    "3. Not necessarily. For example, the both words “bat” (an animal) and “bat” (hitting instrument) are nouns, while there also is the verb “bat” (strike with, or as if with a baseball bat) as in “bat the ball”.\n",
    "4. Not necessarily, For example, “conflict” (verb) has an accent on the second syllable, while “conflict” (noun) has an accent on the first syllable. If two homographs have the same pronunciation, they are called homonyms.\n",
    "5. True, by definition. Words with different spelling and same pronunciation are called homophones, for example too, two and to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.3:</i> <br>\n",
    "</div>\n",
    "\n",
    "N-gram tagging: Which of the following statements are true?\n",
    "\n",
    "1. A trigram tagger is theoretically more accurate than a bigram tagger.\n",
    "2. A trigram tagger looks at the current token and two preceding tags.\n",
    "3. At sentence boundaries, the bigram tagger takes one token of the previous sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. True, in theory, a trigram tagger considers the context of three words to perform the tagging, which should be more accurate than considering only two words like the bigram tagger. However, in practice, the trigram tagger needs a very, very large training corpus to obtain reliable frequency estimates for all possible trigrams. Thus, the accuracy of a trigram tagger trained on a limited corpus might be worse than those of a bigram tagger. However, in practice, “backoff” is used. Thus, the trigram tagger falls back to the bigram tagger in situations where there is not enough training data for a certain trigram.\n",
    "2. True. However, it is also possible to consider both left and right context.\n",
    "3. False, because the tokens in the previous sentences do not help to identify a correct tag for the current token. Usually special tokens representing “Begin-of-Sentence” (BOS) are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.4:</i> <br>\n",
    "</div>\n",
    "\n",
    "Confusion matrix: Which of the following statements are true?\n",
    "1. The major diagonal (╲) elements are always 1.\n",
    "2. Cell (i , j) contains the count of the number of times tag i was classified as tag j.\n",
    "3. The confusion matrix may be used to identify tagging problems.\n",
    "4. The confusion matrix may be used to compare different taggers.\n",
    "5. The number of rows is equal to the number of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "1. False, because the major diagonal elements represent the correctly classified instances.\n",
    "2. True, by the definition of the confusion matrix.\n",
    "3. True, because it helps us to determine how often some label i was wrongly tagged with a label j.\n",
    "4. True, because we may compare the number of errors produced by two taggers.\n",
    "5. True. cell[i, j] demonstrates how many labels i were assigned with a tag j, hence the number of horizontal and vertical rows are equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.5:</i> <br>\n",
    "</div>\n",
    "\n",
    "Given the sentence “The near future promises happiness for all students.”. Tag it manually (using universal tags) and explain which of the following clues were helpful:\n",
    "1. morphological clues\n",
    "2. syntactic clues\n",
    "3. semantic clues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The suggested tagging is “The/DET near/ADJ future/NOUN promises/VERB happiness/NOUN for/ADP all/DET students/NOUN ./.”.\n",
    "1. Morphological clues are useful to determine the part-of-speech of happiness as word with the suffix “-ness” are usually nouns (there are some exceptions, e.g. “to witness”).\n",
    "2. Syntactical clues are useful to disambiguate that future is a noun (it is found in a DET + ADJ + NOUN structure), while promises is a verb (it is found between two noun phrases).\n",
    "3. Semantic clues are not of much use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag(word_tokenize(\"The near future promises happiness for all students.\"), tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.6:</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Many words, like “ski” and “race”, can be used as nouns or verbs with no difference in pronunciation. Can you think of others? <br> Hint: Think of a commonplace object and try to put the word “to” before it to see if it can also be a verb, or think of an action and try to put “the” before it to see if it can also be a noun. Now make up a sentence with both uses of this word, and run the POS-tagger from NLTK on this sentence (using the universal tagset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The phenomenon when a verb becomes noun is called nominalization. Nominalization without any overt changes to the word (called \"conversion\") is very common in English. However, in other languages (for example Russian) verbs and nouns have different suffixes and this phenomenon is very rare. <br>Examples of English nominalized words are \"attack\" or \"sentence\". A recent example is “google” that is now used as a verb, too. <br>Example sentences and their part-of-speech (POS) tags obtained using\n",
    "nltk.pos_tag(nltk.word_tokenize(sentence), tagset=\"universal\")\n",
    " are given in the following table <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l=[\"A bicycle race will be nice.\\nLet's race and see who gets there first.\",\n",
    "   \"His sentence was 5 to 10 years.\\nA judge will sentence him to ten years in prison.\",\n",
    "   \"Google is a search engine that searches for men.\\nShe will google the man she had met at the party\"]\n",
    "for i in range (3):\n",
    "    tok = nltk.pos_tag(nltk.word_tokenize(l[i]), tagset=\"universal\")\n",
    "    print(l[i],\"\\n\")\n",
    "    for i in tok:\n",
    "        print(i[0],\"-->\",i[1],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| words | POS   | Sentence | Parsed Sentence\n",
    "|------|------|------|-----\n",
    "|  race <br> race |noun <br> verb | A bicycle race will be nice <br> Let’s race and see who gets there first |[(’A’, ’DET’), (’bicycle’, ’ADJ’), (’race’, ’NOUN’), (’will’, ’VERB’), (’be’, ’VERB’), (’nice’, ’ADJ’)] <br> [(’Let’, ’VERB’), (“s\", ’PRT’), (’race’, ’NOUN’), (’and’, ’CONJ’), (’see’, ’VERB’), (’who’, ’PRON’), (’gets’, ’VERB’), (’there’, ’ADV’), (’first’, ’ADJ’)]\n",
    "| sentence <br> sentence | noun <br> verb | His sentence was 5 to 10 years. <br> A judge will sentence him to ten years in prison | [(’His’, ’PRON’), (’sentence’, ’NOUN’), (’was’, ’VERB’), (’5’, ’NUM’), (’to’, ’PRT’), (’10’, ’NUM’), (’years’, ’NOUN’), (’.’, ’.’)] <br> [(’A’, ’DET’), (’judge’, ’NOUN’), (’will’, ’VERB’), (’sentence’, ’VERB’), (’him’, ’PRON’), (’to’, ’PRT’), (’ten’, ’VERB’), (’years’, ’NOUN’), (’in’, ’ADP’), (’prison’, ’NOUN’), ('.', '.')]\n",
    "| google <br> google | noun <br> verb | Google is a search engine that searches for men. <br> She will google the man she had met at the party | [(’Google’, ’NOUN’), (’is’, ’VERB’), (’a’, ’DET’), (’search’, ’NOUN’), (’engine’, ’NOUN’), (’that’, ’DET’), (’searches’, ’VERB’), (’for’, ’ADP’), (’men’, ’NOUN’), (’.’, ’.’)] <br> [(’She’, ’PRON’), (’will’, ’VERB’), (’google’, ’VERB’), (’the’, ’DET’), (’man’, ’NOUN’), (’she’, ’PRON’), (’had’, ’VERB’), (’met’, ’VERB’), (’at’, ’ADP’), (’the’, ’DET’), (’party’, ’NOUN’)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The verb “race” is incorrectly tagged as “NOUN” in the second sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.7:</i> <br>\n",
    "</div>\n",
    "\n",
    "Different words that have the same written form are called homographs. A simplified definition is that homographs are words with the same spelling (case sensitive) and different POS. <br><br>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.7.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Take a look at the function below, what will be printed on the console if it is executed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown.tagged_words(tagset='universal'))\n",
    "print(tag_fd.N())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The function will extract all tagged tokens from the corpus and includes each in a frequency distribution with the token and its universal tag. The output contains the total number of sample outcomes that have been recorded by the frequency distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.7.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "As the function above is quite useless in its current form, it needs to be improved. Do so by changing it so that the output contains all POS tags (universal) that are used in a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown.tagged_words(tagset='universal'))\n",
    "print(tag_fd.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Brown Corpus: DET, NOUN, ADJ, VERB, ADP, ., ADV, CONJ, PRT, PRON, NUM, X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.7.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the function again so that it finds all homographs (using the universal definition) within a corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "To see that we really use a simplification for homographs, type the word “bass” into www.leo.org and check the different meanings of the listed nouns. Solution code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((word, tag) for word, tag in brown.tagged_words(tagset='universal'))\n",
    "\n",
    "homographs = [key for key in cfd.keys() if len(cfd[key]) > 1]\n",
    "\n",
    "for homograph in homographs:\n",
    "    print(homograph)\n",
    "    print(cfd[homograph].keys())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.8:</i> <br>\n",
    "</div>\n",
    "\n",
    "Write programs to process the Brown Corpus and find answers to the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "What is the output of the function below? Proof your answer by executing it on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = FreqDist([word for (word,tag) in brown.tagged_words(tagset='universal') if tag == 'NOUN'])\n",
    "print([i for i in n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The function prints each token from the corpus that is tagged as a noun in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different corpora don't necessarily employ the same tagset. In the following we will inspect the brown corpus and its original tagset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "What are the 10 most frequent tags in the Brown Corpus using the original Brown tagset (instead of the universal tagset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_fd_br = FreqDist(tag for (word, tag) in brown.tagged_words())\n",
    "print([j for j in (tag_fd_br.most_common(10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "What do these tags stand for? Print 10 example words for each tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in (tag_fd_br.most_common(10)):\n",
    "    fd_word_br = FreqDist(word for (word, tag) in brown.tagged_words() if tag == y[0])\n",
    "    print(y[0],\"example words\\n\",[i[0] for i in fd_word_br.most_common(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.4</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Change the function from task 3.8.1 so that the output contains the 5 most frequent singular and the 5 most frequent plural nouns from the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = FreqDist([word for (word,tag) in brown.tagged_words() if tag == 'NN'])\n",
    "ns = FreqDist([word for (word,tag) in brown.tagged_words() if tag == 'NNS'])\n",
    "\n",
    "print(\"Singular:\", n.most_common(5))\n",
    "print(\"Plural:\", ns.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For the Brown Corpus, the output is: Singular: [time, man, Af, way, world], Plural: [years, people, men, States, eyes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.8.5</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Which nouns are more common in their plural form, rather than their singular form? Change the function again to find out! (Only consider regular plurals, formed with the -s suffix.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "Refer to the code in the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = brown.tagged_words()\n",
    "fdistSg = nltk.FreqDist([word for (word,tag) in corpus if tag == 'NN'])\n",
    "fdistPl = nltk.FreqDist([word for (word,tag) in corpus if tag == 'NNS' and word[-1] == \"s\"])\n",
    "\n",
    "for word in fdistPl.keys():\n",
    "    if fdistPl[word] > fdistSg[word[:-1]]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.9:</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "In the Brown corpus, what percentage of words are tagged with the first five most common original tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in brown.tagged_words())\n",
    "sum = 0\n",
    "for i in tag_fd.most_common(5):\n",
    "   sum += i[1]\n",
    "print(sum/tag_fd.N() * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five tags cover about 43% of all tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.10:</i> <br>\n",
    "</div>\n",
    "\n",
    "Generate some statistics for tagged data to answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.10.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "Take a look at the code below. What does it compute? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist([(word.lower(),tag) for (word, tag) in brown.tagged_words()])\n",
    "nr_tags_cfd = nltk.ConditionalFreqDist([(len(cfd[word]), word) for word in cfd.conditions()])\n",
    "\n",
    "nr_of_tags = 1\n",
    "print(\"words with one tag:\", len(nr_tags_cfd[nr_of_tags]))\n",
    "print(\"ratio:\", float(len(nr_tags_cfd[nr_of_tags]))/len(cfd.conditions()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "The Code computes the proportion of how many word types are always assigned the same POS tag. For the Brown corpus, there are 40235 types that appear with only one (non-universal) POS-tag. This are 81% of all word types in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.10.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "How many words are ambiguous, in the sense that they appear with at least two tags (no programming required)? Change the function above so that it computes the percentage of word tokens that involve these ambiguous words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist([(word.lower(),tag) for (word, tag) in brown.tagged_words()])\n",
    "nr_tags_cfd = nltk.FreqDist([len(cfd[word]) for word in brown.words()])\n",
    "\n",
    "print(\"ambigious words:\", len(brown.words()) - nr_tags_cfd[1])\n",
    "print(\"ratio:\", float(1 - nr_tags_cfd[1]/len(brown.words())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19% of the words in the corpus are ambiguous (can simply induced from 3.10.1 without any programming). The overall ratio of ambiguous tokens in the Brown Corpus is 87%. This means that a small amount of 19% ambiguous types correspond to a large number of ambiguous tokens. It is a known linguistic phenomenon that frequent words are more ambiguous than seldom occurring words (see Zipf distribution in lecture)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.10.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Which words in the Brown corpus have the highest number of distinct tags?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd= nltk.ConditionalFreqDist((word.lower(),tag) for (word,tag) in brown.tagged_words())\n",
    "nr_tags_cfd = nltk.ConditionalFreqDist([(len(cfd[word]), word) for word in cfd.conditions()])\n",
    "\n",
    "highest_nr_tags=max(nr_tags_cfd.conditions())\n",
    "print(\"Highest # of tags:\", highest_nr_tags)\n",
    "print(\"Words with \",highest_nr_tags,\"tags: \", ', '.join(nr_tags_cfd[highest_nr_tags].keys()))\n",
    "for word in nr_tags_cfd[highest_nr_tags].keys():\n",
    "    print(word, \"-->\", ' '.join(cfd[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest number of tags is 15. There is one word with 15 different tags: that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.11:</i> <br>\n",
    "</div>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.11.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Look at the code below, explain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordTagCfd = nltk.ConditionalFreqDist([(word.lower(),tag) for (word, tag) in brown.tagged_words(tagset='universal')])\n",
    "\n",
    "def getASentence():\n",
    "    #TODO\n",
    "def getMostLikelyTag():\n",
    "    #TODO\n",
    "\n",
    "getASentence(brown.tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "A conditional frequency distribution ”wordTagCfd” is created, that includes each word of the brown corpus together with the universal tag of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.11.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "We now want to give the code a little bit more functionality. As you can see, the method getASentence is called, but at the moment, it will not do anything. Enhance it so that when called, it will print out each token of a sentence in the Brown corpus (Hint: getASentence(40) will return sentence number 41, not 40)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordTagCfd = nltk.ConditionalFreqDist([(word.lower(),tag) for (word, tag) in brown.tagged_words(tagset='universal')])\n",
    "\n",
    "def getASentence(nr):\n",
    "    x = brown.tagged_sents(tagset='universal')[nr]\n",
    "    for i in x:\n",
    "        print (i[0])\n",
    "def getMostLikelyTag():\n",
    "    #TODO\n",
    "    \n",
    "getASentence(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sentence 41:\n",
    "Hartsfield has\n",
    "been mayor\n",
    "of Atlanta\n",
    ",\n",
    "with exception of\n",
    "one\n",
    "brief interlude ,\n",
    "since 1937\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.11.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "We now want the tag for each token of the sentence. Enhance the method getMostLikelyTag so that the most likely tag for a token is returned (use the wordTagCfd as a lookup dictionary and test your method on a sentence from the Brown corpus).\n",
    "Then change the method getASentence again so that not only each token, but also the tag of the token is printed out in the console.\n",
    "Test your method on a sentence from the Moby Dick corpus. How well does it perform? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordTagCfd = ConditionalFreqDist([(word,tag) for (word, tag) in brown.tagged_words(tagset='universal')])\n",
    "\n",
    "def getASentence(x):\n",
    "    for i in x:\n",
    "        print(i, '-', getMostLikelyTag(i, wordTagCfd))\n",
    "        \n",
    "def getMostLikelyTag(word, lookup_cfd):\n",
    "    tag = 'UNK'\n",
    "    if word in lookup_cfd.conditions():\n",
    "        tag = lookup_cfd[word].max()\n",
    "    return tag\n",
    "\n",
    "print(\"Brown corpus:\")\n",
    "getASentence(brown.sents()[40])\n",
    "print(\"\\nMoby Dick corpus:\")\n",
    "getASentence(text1[42:73])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several tokens from the Moby Dick corpus have no tag assigned to them (marked with UNK), as they did not appear in the data used for training the tagger (Brown corpus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 3.12:</i> <br>\n",
    "</div>\n",
    "\n",
    "Explore the n-gram taggers for n ∈ 1, 2, 3 in the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "train_sents = brown.tagged_sents(tagset='universal')\n",
    "t1 = nltk.UnigramTagger(train_sents)\n",
    "t2 = nltk.BigramTagger(train_sents)\n",
    "t3 = nltk.TrigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.12.1</i><br>\n",
    "</div>\n",
    "\n",
    "Manually tag the sentence “The only conservative councillor representing Cambridge resigned from the city council.” using the universal tagset. Represent it as a tagged sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>\n",
    "\n",
    "|Word|Correct\n",
    "|-|-\n",
    "|The|DET\n",
    "|only | ADJ\n",
    "|conservative |ADJ\n",
    "|councillor |NOUN\n",
    "|representing |VERB\n",
    "|Cambridge | NOUN\n",
    "|resigned| VERB\n",
    "|from |ADP\n",
    "|the| DET\n",
    "|city |NOUN\n",
    "|council|NOUN\n",
    "|.|.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['The', 'only', 'conservative', 'councillor', 'representing', 'Cambridge', 'resigned', 'from', 'the', 'city', \n",
    "            'council', '.']\n",
    "tagged_sentence = [('The', 'DET'), ('only', 'ADJ'), ('conservative','ADJ'), ('councillor','NOUN'), ('representing','VERB'),\n",
    "                   ('Cambridge','NOUN'),( 'resigned','VERB'),( 'from','ADP'), ('the','DET'), ('city','NOUN'), \n",
    "                   ('council','NOUN'), ( '.','.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.12.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "We now want to evaluate the performance of different n gram taggers. Enhance the the code using the function tagger.evaluate(sentences) so that all four taggers are evaluated on the sentence from task 2.12.1 The default tagger is already implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t0.tag(sentence))\n",
    "print(t0.evaluate([tagged_sentence]))\n",
    "print(t1.tag(sentence))\n",
    "print(t1.evaluate([tagged_sentence]))\n",
    "print(t2.tag(sentence))\n",
    "print(t2.evaluate([tagged_sentence]))\n",
    "print(t3.tag(sentence))\n",
    "print(t3.evaluate([tagged_sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the bigrams and trigrams in the sentence are not found in the corpus. Thus, the performance of the n-gram taggers decreases with increasing n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.12.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "The idea of backoff tagging is to rely on other taggers when the current tagger cannot assign a label. For example, a bigram tagger might never encounter some bigram, however a unigram tagger may separately tag the single words in the bigrams. In this task, we will explore the contribution of n-gram taggers for n ∈ 1, 2, 3 in the backoff setup, provided by the following listing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = nltk.DefaultTagger('NOUN')\n",
    "train_sents = brown.tagged_sents(tagset='universal')\n",
    "t1 = nltk.UnigramTagger(train_sents, backoff = t0)\n",
    "t2 = nltk.BigramTagger(train_sents, backoff = t1)\n",
    "t3 = nltk.TrigramTagger(train_sents, backoff = t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the sentence “The only Conservative councillor representing Cambridge resigned from the city council.“ using the taggers t0, t1, t2, and t3 with backoff tagging and evaluate the results like in task 3.12.2). Compare the results with and without backoff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color: blue\">Lösung:</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t0.tag(sentence))\n",
    "print(t0.evaluate([tagged_sentence]))\n",
    "print(t1.tag(sentence))\n",
    "print(t1.evaluate([tagged_sentence]))\n",
    "print(t2.tag(sentence))\n",
    "print(t2.evaluate([tagged_sentence]))\n",
    "print(t3.tag(sentence))\n",
    "print(t3.evaluate([tagged_sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the default tagger is unchanged, as it is as dumb as before :) The unigram tagger improves a little bit, as in case of unknown words it can now backoff to the default tagger. As the probability that unseen words are nouns is quite high, this gives some improvements. The bigram tagger improves dramatically, as it backs off to the unigram tagger when it cannot recognize a bigram. The behavior of the trigram tagger is identical to the bigram tagger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 3.1:</i>\n",
    "        ::: 5 Homework points :::</div>\n",
    "                                \n",
    "Write code to search the Brown Corpus for particular words and phrases according to tags (universal tagset), to answer the following questions: <br><br>\n",
    "\n",
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.1</i>\n",
    "</div>\n",
    "Produce an alphabetically sorted list of the distinct words tagged as ADP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.2</i>\n",
    "</div>\n",
    "\n",
    "Identify words that can be plural nouns or third person singular verbs (e.g. deals, flies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.3</i>\n",
    "</div>\n",
    "\n",
    "For the word(s) with the greatest number of distinct tags, print the sentences from the corpus containing the word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">3.1.4</i>\n",
    "</div>\n",
    "\n",
    "What is the ratio of masculine to feminine pronouns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 3.2:</i>\n",
    "        ::: 5 Homework points :::</div>\n",
    "        \n",
    "\n",
    "Print a table with the integers 1..10 in one column, and the number of types in the corpus having 1..10 distinct tags in the other column."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
